{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Definition Finder\n",
    "- Definition Source：Baidu, Zhihu, reciBaike, GengBaike, lxyBaike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup \n",
    "from lxml import etree\n",
    "import csv,codecs\n",
    "import re\n",
    "import xlsxwriter\n",
    "import math\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_def(word):\n",
    "    ret = []\n",
    "    ret.append(\"梗百科： \" + find_gbk('梗百科.csv',word))\n",
    "    ret.append(\"流行语百科： \" + find_lyx('lxyBaike.csv',word))\n",
    "    ret.append(\"热词百科： \" +find_reci('reciBaike.csv',word))\n",
    "    search_term = word + \"是什么梗 知乎\"\n",
    "    baidu = []\n",
    "    zhihu = []\n",
    "    try:\n",
    "        zhihu = Get_zhihu(search_term, 1, word)\n",
    "    except Exception as e:\n",
    "        print(\"知乎bug\")\n",
    "        \n",
    "    try:\n",
    "        baidu = find_baidu(word)\n",
    "    except Exception as e:\n",
    "        print(\"百度bug\")\n",
    "    ret = ret + baidu + zhihu\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baidu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_baidu(word):   \n",
    "    ret = []\n",
    "    headers = { \n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'\n",
    "    }\n",
    "    url='https://baike.baidu.com/item/'+word      \n",
    "    try:\n",
    "        response = requests.get(url,headers=headers)\n",
    "\n",
    "        #将一段文档传入BeautifulSoup的构造方法,就能得到一个文档的对象, 可以传入一段字符串\n",
    "        soup = BeautifulSoup(response.text,'lxml')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    definition = soup.find(property=\"og:description\")['content']\n",
    "    s= soup.get_text()\n",
    "    origin = \"\"  #词语来源\n",
    "    development = \"\" #词语发展\n",
    "    example = \"\" #引用示例\n",
    "\n",
    "    if ((word+\"词语来源\") in s):\n",
    "        origin = s.split(word+\"词语来源\")[1].replace(\"\\n\",\"\").split(\"\\xa0\")[0].replace(\"编辑语音\",\"\")\n",
    "    if ((word+\"词语发展\") in s):\n",
    "       development =s.split(word+\"词语来源\")[1].replace(\"\\n\",\"\").split(\"\\xa0\")[0].replace(\"编辑语音\",\"\")    \n",
    "    if ((word+\"引用示例\") in s):\n",
    "       example =s.split(word+\"引用示例\")[1].replace(\"\\n\",\"\").split(\"\\xa0\")[0].replace(\"编辑语音\",\"\")    \n",
    "        \n",
    "        \n",
    "    ret.append(definition)\n",
    "    ret.append(origin)\n",
    "    ret.append(development)\n",
    "    ret.append(example)\n",
    "    return ret\n",
    "\n",
    "def get_baidu(word):\n",
    "    try:\n",
    "        res = find_baidu(word)\n",
    "        for i in range(len(res)):\n",
    "            if (len(res[i]) != 0):\n",
    "                print(res[i] + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(\"该词未被百度收录。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lxyBaike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_lyx(link,word):\n",
    "    df = pd.read_csv(link)\n",
    "    ret = \"流行语百科未收录该词。\"\n",
    "    if (word in df[\"词条\"].values):\n",
    "        ret=(df.loc[df['词条'] == word]['摘要'].iloc[0])\n",
    "    return ret\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reciBaike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_reci(link,word):\n",
    "    df = pd.read_csv(link)\n",
    "    ret = \"热词百科未收录该词。\"\n",
    "    if (word in df[\"word\"].values):\n",
    "        ret=(df.loc[df['word'] == word]['explanation'].iloc[0])\n",
    "    return ret\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gengBaike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gbk(link,word):\n",
    "    df = pd.read_csv(link, names=['word','def'], index_col=False)\n",
    "    ret = \"梗百科未收录该词。\"\n",
    "    if (word in df[\"word\"].values):\n",
    "        ret=\"梗百科解释：\" + (df.loc[df['word'] == word]['def'].iloc[0])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zhihu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zhihu(url, word):\n",
    "    ret = []\n",
    "    headers = { \n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'\n",
    "    }   \n",
    "    try:\n",
    "        response = requests.get(url,headers=headers)\n",
    "\n",
    "\n",
    "        soup = BeautifulSoup(response.text,'lxml')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "        \n",
    "#     只取中文和标点\n",
    "#     t= re.findall('[\\u3002\\uff1b\\uff0c\\uff1a\\u201c\\u201d\\uff08\\uff09\\u3001\\uff1f\\u300a\\u300b\\u4e00-\\u9fa5]',s)\n",
    "#     print(''.join(t))       \n",
    "        \n",
    "    test = soup.select('span[name]')\n",
    "    for x in soup.find_all(\"span\"):\n",
    "        if (word in x.get_text()):   \n",
    "            ret.append(x.get_text())\n",
    "    ret = \"\\n\".join(ret)\n",
    "    return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def convert_url(url):\n",
    "    headers = { \n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'\n",
    "    }   \n",
    "    resp = requests.get(url=url,\n",
    "                        headers=headers,\n",
    "                        allow_redirects=False, \n",
    "                        verify=False\n",
    "                        )\n",
    "    return resp.headers['Location']\n",
    "\n",
    "    \n",
    "def get_url(wd,num, search_term):\n",
    "    \n",
    "    headers = { \n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'\n",
    "    }   \n",
    "    info = []\n",
    "    s = requests.session()\n",
    "    total_title=[]\n",
    "    total_url=[]\n",
    "    total_info=[]\n",
    "\n",
    "    num=num*10-10\n",
    "    for i in range(-10, num, 10):\n",
    "        url = 'https://www.baidu.com/s'\n",
    "        params = {\n",
    "            \"wd\": wd,\n",
    "            \"pn\": i,\n",
    "        }\n",
    "        r = s.get(url=url, headers=headers, params=params,verify=False)\n",
    "        print(\"返回状态码:\",r.status_code) \n",
    "        soup = BeautifulSoup(r.text, 'lxml')\n",
    "        for so in soup.select('#content_left .t a'):\n",
    "            g_url = convert_url(so.get('href'))\n",
    "            g_title=so.get_text().replace('\\n','').strip()\n",
    "#             print(g_title,g_url)\n",
    "            total_title +=[g_title]\n",
    "            total_url +=[g_url]\n",
    "        time.sleep(1 + (i / 10))\n",
    "        \n",
    "        zhihu_num = 0\n",
    "        for ur in total_url:\n",
    "#             print(ur)\n",
    "            if (\"zhihu\" in ur):\n",
    "                app = extract_zhihu(ur,search_term)\n",
    "                info.append(app)\n",
    "                zhihu_num +=1\n",
    "        print(\"Found \" + str(zhihu_num) + \"zhihu links\")\n",
    "\n",
    "        return info\n",
    "\n",
    "def Get_zhihu(wd, page, search_term):   \n",
    "    if __name__ == '__main__':\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:73.0) Gecko/20100101 Firefox/73.0\",\n",
    "            \"Host\": \"www.baidu.com\",\n",
    "        }\n",
    "        return get_url(wd,1,search_term)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Come Search！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a slang： 打野\n",
      "enter 'quit' to quit loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Eric/opt/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "返回状态码: 200\n",
      "Found 10zhihu links\n",
      "梗百科： 梗百科未收录该词。\n",
      "\n",
      "\n",
      "流行语百科： 流行语百科未收录该词。\n",
      "\n",
      "\n",
      "热词百科： 在moba类(塔防类)游戏，比如英雄联盟或者王者荣耀中，打野是一个玩家位置，常规任务之一就是打野怪，可以通过打野怪得到经验值和金币。\n",
      "\n",
      "\n",
      "打野，汉语词汇，拼音是dǎ yě，解释是亦称“打野呵”。谓艺人在街头卖艺。&amp;nbsp;方言。广西壮族自治区桂林话，意指“开小差”、“不专心”、“三心二意”。方言。犹言捞外快。\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "打野就是指打死野生动物。今天给大家介绍一位中国野王。何广位是1909年出生，2004年去世，享年95岁，是一位长寿的传武大师，本来是安徽人，后来流亡到了河南。自幼天生神力，饭量惊人。他14岁的时候拜江湖卖艺的一位名叫王进的大师为师，学习了一套惊奇的拳法。之后由于和几名鬼子激战搏斗，被迫和恩师分道扬镳。之后独立行走江湖的何广位还曾经路见不平一声吼，打死过两名调戏妇女的日本鬼子。要说何广位真是苦命人，他饥不择食，生活窘迫，偶然间三拳两脚打死了一只野狼，后来拿到了集市上去卖，卖了30大洋。之后尝到甜头的何广位开始以打猎为生。期间他总共打死和活捉7只猛虎，9头野牛，230多只金钱豹，800多只野猪和1000多只恶狼，堪称当代活武松。他靠的就是一双拳头，比武松还硬的拳头。何广位身高1米8多，体格极其健壮，力大无穷，还曾经在山西为民除害，徒手击毙一只金钱豹，被当地传为佳话，而且庆功宴上喝了7斤白酒，比武松还要能打，还能喝。要说何广位为何能有如此神勇的表现，笔者认为绝对力量是第一位的，其次就是仗着师父教给他的一套精湛拳法。两者相结合，才造就了何老英雄的辉煌战绩。如果何广位可以和现在的搏击拳手比武，笔者认为他完全可以一拳KO任何一位搏击拳手，毕竟绝对力量太强悍。太极雷雷、咏春大师余昌华、两仪拳大师吕刚，里合腿田野等人虽然也都是传武高手，但是他们缺乏绝对力量，尽管招式奇特，但无法和真正的搏击拳手对抗，往往遭遇被KO的结果。但是何广位则不同，他身材高大，多年的猎户生涯造就他的抗打能力超强，我们可以想象，他击毙或者活捉2000多只猛兽，不可能没有受过伤，如果没有超强的抗打能力，恐怕早就成为老虎的腹中餐了。反正我全是复制粘贴过来的，我看完我也信了，至于你信不信随便吧······中国第一打野~\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "这是职业选手的日常训练内容之一，现在越来越多的高端玩家也在模仿这一训练方式。酒吧。嘈杂，拥挤，喧闹，再加上酒精对大脑的麻痹作用。选手在这个时候打野需要更加精细的操作，更加准确的判断，更加风骚的走位来压制对手，带领团队走向胜利。以及更加老辣的摇色技术来避免让自己喝多。总而言之，这是一个集线上线下，心理身理，个人技术及团队配合，三位一体的高强度训练方式，一般人最好不要轻易尝试\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "打野（英雄联盟英雄定位）\n",
      "\n",
      "\n",
      "问题很简陋，也因此所有有关打野的话与见解，都可以在这里阐述（教教题主 ），比如打野应该做什么，什么时候做，怎么做...我很喜欢打野这个位置，但我的水平…\n",
      "\n",
      "\n",
      "这是职业选手的日常训练内容之一，现在越来越多的高端玩家也在模仿这一训练方式。酒吧。嘈杂，拥挤，喧闹，再加上酒精对大脑的麻痹作用。选手在这个时候打野需要更加精细的操作，更加准确的判断，更加风骚的走位来压制对手，带领团队走向胜利。以及更加老辣的摇色技术来避免让自己喝多。总而言之，这是一个集线上线下，心理身理，个人技术及团队配合，三位一体的高强度训练方式，一般人最好不要轻易尝试\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "姜子牙打野？我的天！我偷偷上分的利器被发现了！众所周知，姜子牙被动使得前期能带给队友巨大收益，也就是说，就算不抓边也能给队友带来收益，厉害不。一二技能又有高额减抗，又高额减速，又能留人又有输出。。。厉害不。三技能，那叫一个神技！超远距离，超大范围，杀人于千里之外，自己丝血不掉。厉害不。如此强势的打野通常选出来就是一打九，相信游戏很快就能结束。想要上分的小伙伴快来试试这强势的打野英雄吧！六分一局，比养猪流高效实用！\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    while True:#循环\n",
    "        w = input(\"Enter a slang： \")\n",
    "        print(\"enter 'quit' to quit loop.\")\n",
    "        if (w == \"quit\"):\n",
    "            break;\n",
    "        ret = find_def(w)\n",
    "        for i in range(len(ret)):\n",
    "            print(ret[i])\n",
    "            print('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
